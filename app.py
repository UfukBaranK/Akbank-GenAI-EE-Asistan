import os
import streamlit as st
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
    
# .env dosyasÄ±ndaki anahtarlarÄ± yÃ¼kle
load_dotenv()

# KRÄ°TÄ°K BÃ–LÃœM: API AnahtarÄ±nÄ± KÃ¼tÃ¼phanenin OkuyacaÄŸÄ± Åekilde Garanti AltÄ±na Al
API_KEY_VALUE = os.getenv("GEMINI_API_KEY")
if not API_KEY_VALUE:
    API_KEY_VALUE = os.getenv("GOOGLE_API_KEY") # GOOGLE_API_KEY'i de kontrol et
    
if API_KEY_VALUE:
    os.environ["GEMINI_API_KEY"] = API_KEY_VALUE
    os.environ["GOOGLE_API_KEY"] = API_KEY_VALUE # SDK'nÄ±n okumasÄ± iÃ§in set et
else:
    print("ğŸš¨ HATA: .env dosyasÄ±nda geÃ§erli bir API AnahtarÄ± bulunamadÄ±.")
    
# -- Sabitler --
VECTOR_DB_PATH = "./vector_db"
GEMINI_MODEL = "gemini-2.5-flash"
EMBEDDING_MODEL = "models/embedding-001"
    
def setup_rag_chain():
    # API AnahtarÄ±nÄ±n varlÄ±ÄŸÄ±nÄ± kontrol et
    if not os.environ.get("GEMINI_API_KEY") and not os.environ.get("GOOGLE_API_KEY"):
        st.error("ğŸš¨ HATA: API AnahtarÄ± bulunamadÄ±. LÃ¼tfen .env dosyasÄ±nÄ± kontrol edin.")
        return None
        
    # VeritabanÄ± kontrolÃ¼
    if not os.path.exists(VECTOR_DB_PATH):
        st.error(f"ğŸš¨ HATA: VeritabanÄ± yok. LÃ¼tfen Ã¶nce terminalde 'python ingest.py' komutunu Ã§alÄ±ÅŸtÄ±rÄ±n.")
        return None
    
    # 1. VektÃ¶r VeritabanÄ±nÄ± geri yÃ¼kle
    embeddings = GoogleGenerativeAIEmbeddings(model=EMBEDDING_MODEL)
    vectorstore = Chroma(persist_directory=VECTOR_DB_PATH, embedding_function=embeddings)
    
    # RAG KAPSAMINI GENÄ°ÅLETTÄ°K (k=5): En alakalÄ± 5 metin parÃ§asÄ±nÄ± Ã§ek.
    retriever = vectorstore.as_retriever(search_kwargs={"k": 5}) 
    
    # 2. LLM ve GeliÅŸmiÅŸ TÃ¼rkÃ§e Prompt
    llm = ChatGoogleGenerativeAI(model=GEMINI_MODEL, temperature=0.1)

    # ESNEK PROMPT: BaÄŸlam yetersizse LLM'in genel bilgisini kullanmasÄ±nÄ± saÄŸlÄ±yor.
    template = """Sen, Elektrik-Elektronik MÃ¼hendisliÄŸi Ã¶ÄŸrencilerine yÃ¶nelik pratik bir ders asistanÄ±sÄ±n. 
    GÃ¶revin, kullanÄ±cÄ±nÄ±n sorusuna **enerjik ve profesyonel** bir tonda **detaylÄ± TÃœRKÃ‡E cevap** vermektir.

    **KURAL:**
    1. **Ã–ncelikli olarak** aÅŸaÄŸÄ±daki 'BaÄŸlam' kÄ±smÄ±nda bulunan bilgileri kullan.
    2. EÄŸer 'BaÄŸlam'da soruya dair **yeterli veya net bir cevap yoksa**, genel mÃ¼hendislik bilgini ve temel kavramlarÄ± kullanarak soruyu yanÄ±tla.
    3. CevabÄ±nÄ± her zaman profesyonel ve yapÄ±landÄ±rÄ±lmÄ±ÅŸ bir dille sun.

    BaÄŸlam: 
    {context}

    Soru: {question}

    TÃœRKÃ‡E Cevap:"""
    prompt = ChatPromptTemplate.from_template(template)
    
    # 3. LCEL ile RAG Zincirini Kurma
    rag_chain = (
        {"context": retriever | (lambda x: "\n\n".join([doc.page_content for doc in x])), "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )
    return rag_chain
    
# Streamlit Ana Fonksiyon
def main():
    st.set_page_config(page_title="EE Ders AsistanÄ±", layout="wide")
    
    # -------------------------------------------------------------
    # GÃœNCELLENMÄ°Å BAÅLIK VE AÃ‡IKLAMA (Son Hali)
    # -------------------------------------------------------------
    st.title("ğŸ’¡ Elektrik-Elektronik MÃ¼hendisliÄŸi AsistanÄ± (RAG)")
    st.caption("ğŸ” Hacettepe EE Ders KitaplarÄ± ve YardÄ±mcÄ± Kaynaklara DayalÄ±, Gemini Destekli AkÄ±llÄ± Asistan.")
    # -------------------------------------------------------------
    
    if 'rag_chain' not in st.session_state:
        st.session_state.rag_chain = setup_rag_chain()
        if st.session_state.rag_chain is None:
            return
    
    user_question = st.text_input("EE Ders KitaplarÄ±na dair teknik bir soru sor:", 
                                  placeholder="Ã–rn: 'ELE320 dersinden DÄ±ÅŸ Kaynaktan Beslenen BJT'nin DC Analizini aÃ§Ä±klar mÄ±sÄ±n?'")
    
    if user_question:
        with st.spinner("ğŸš€ Bilgi KaynaklarÄ±n TaranÄ±yor..."):
            try:
                response = st.session_state.rag_chain.invoke(user_question)
                st.success("Cevap HazÄ±r!")
                st.markdown(f"**Asistan YanÄ±tÄ±:** \n\n {response}")
            except Exception as e:
                st.error(f"Hata Kodu: {e}")
                st.warning("Uygulama aÃ§Ä±ldÄ±ysa ve bu hatayÄ± alÄ±yorsanÄ±z: gÃ¼nlÃ¼k kota dolmuÅŸ olabilir veya API anahtarÄ±nÄ±z Google Cloud'da kÄ±sÄ±tlanmÄ±ÅŸtÄ±r.")
    
if __name__ == "__main__":
    main()

# ğŸƒ Ã‡alÄ±ÅŸtÄ±rma Komutu: streamlit run app.py